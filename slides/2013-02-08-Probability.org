* Probability :slide:

* Nomenclature :slide:
  + Record :: a single entity or concept. Also: data object, sample, example,
    instance, data point
  + Feature :: a characteristic or way of describing a record. Also: attribute,
    dimension, variable, signal
** Slightly different from book :notes:
   + The meanings do carry different connotations, but are generally
     transferable
   + Eg. dimensions is usually used in the math domain
   + Feature is usually used in the ML domain

** Feautre Types :slide:
  + Binary :: True/False. Also: 0/1
  + Numeric :: Involving numbers. Also: integer, float, double
  + Ordinal :: Feature with sortable values.
  + Discrete :: countable, finite set. Also: classes
  + Continuous :: unbounded numeric number. Also: integer, float, double
  + Enumerated :: feature named, discrete values. Also: nominal, classed
*** Rain data set :notes:
   + Stored did/dot not rain
   + Stored how many inches it rained
   + Stored the day as an integer offset from Jan 1 1970
   + Stored weather information: Sunny, Partly Sunny, Cloudy, Rainy
   + Stored barometer reading
   + Stored day of the week

* Central Tendency :slide:
[[file:skew-normal.png]]
** Define :notes:
   + Mean :: "average" all data points divided by size of set
   + Median :: middle value
   + Mode :: The value most likely to be picked
     + discrete :: most common value
     + continuous :: max probability density function

** Skew Positive :slide:
[[file:skew-positive.png]]
** Skew :notes:
   + Think about =mean - mode=
   + Or think about where the "tail" is

** Skew Negative :slide:
[[file:skew-negative.png]]

* The Long Tail :slide:
[[file:Long_tail.svg.png]]
  + Most popular are *very* popular
  + Everything else, not so much
  + But there's a lot of everything else
** Movies :notes:
   + Current releases: millions of people watching
   + Older movies are rented by < 1 person a week
   + What is the skew?

* Dispersion :slide:
[[file:dispersion.png]]
  + Centrality not the whole story
** Differences :notes:
   + Wildly different data sets can still share many of these characteristics

* Quartiles :slide:
[[file:quartiles.png]]
** Parts :notes:
   + Go back to our unskewed normal distribution
   + Quartiles divide the data into quarters
   + InterQuartile Range is the distance of the middle two quartiles
   + BoxPlot is one of the most useful tools for data. For public results, I
     almost never want to see scatter plot or bar charts. I want to see box
     plots.
   + Bottom, we spit it up into standard deviations
   + Variance measures, on average, how far points are away from the mean
   + Standard deviation is the square root of the variance

* Standard Deviation :slide:
  [[file:stddev.png]]
  + Within 1: 68%
  + Within 2: 95%
  + Within 3: 99.7%
** Standard Deviation :notes:
   + Useful for thinking about what % of outliers you'd like to catch
   + We use it for alerting: let us know when we're 2 stddev away from the
     median, there's a very small likelihood of that happening

* Visualization Tools :slide:
  + Python: Matplotlib
  + R: builtin
  + Matlab: builtin
  + Octave: builtin (gnuplot)
  + HTML: D3.js
** Covered later :notes:
   + Chapter 2 is going to cover some visualization stuff
   + We're going to cover visualization a bit later in the course, and more of a
     "how its done in industry"
   + There is another class on visualization in general

* Mathmatical Representation :slide:
|        | Bad Boys | Robin Hood | Water World | 
| Prabha | 1        | 3          | 2           | 
| AJ     | 5        | 4          | 3           | 
| Victor | 4        | 4          | 1           | 
#+begin_src octave
[ 1 3 2
  5 4 3
  4 4 1 ]
#+end_src
** Matrix :notes:
   + Matrix representations very powerful, as we'll see later in class
   + Usually rows are records, columns are attributes
   + Sometimes you can think of data in different ways, can take the transpose
     of the matrix to get attributes about movies

* Waterworld :slide:
  [[file:waterworld.jpg]]

* Similarity | Distance :slide:
  + Two sides of the same coin
  + =similarity = 1 - distance=
  + We'll use these metrics for many other algorithms
** Core Concept :notes:
   + Many data mining techniques rely on finding a way to quantify similarity
   + When you think about questions like "how similar are two users?" "is this
     text plagiarism?" "are these products likely to be purchased together?"
   + All are ways of thinking about similarity

* Nominal Distance :slide:
  + Ratio of mismatches to potential matches
  + Why can't we take the sum of the mismatches?
** Nominal :notes:
   + Nominal means we can't compare two values: there is no ordering
   + All we can do is take ratio of the ones that are exactly the same
   + The book describes how to think about this in terms of matrices

* Binary Distance :slide:
  + Could use Nominal Distance: count all exact matches or mismatches
  + Could use Numeric Distance: just treat values as 0/1
  + asymmetric binary dissimilarity: don't care about *negative matches*
    + =mismatches / (positive_matches + mismatches)=
  + asymmetric binary similarity: care more about *positive matches* than mismatches
    + =positive_matches / (positive_matches + mismatches)=
** Binary :notes:
   + Nominal problem: for rare attributes, like a disease, two people who
     *don't* have the disease, aren't necessarily very similar

* Jaccard Coefficient :slide:
  + Asymmetric binary similarity
  + More commonly used for calculating set similarity
  + =|intersection| / |union|=
  + "Jim likes pizza" | "Shreyas likes pizza"
** Jaccard :notes:
   1. Break up into a set
   1. calculate # in intersection
   1. calculate # in union
   1. divide

* Euclidean distance :slide:
  + Straight line between two points
  + Again: usually considered with just (x,y), but can calculate for any number
    of dimensions
  [[file:euclidean.png]]
** Ordinary :notes:
   + Distance as you probably learned in grade school

* Manhattan distance :slide:
  + How many blocks would you need to walk between two points?
  [[file:manhattan.png]]
** Usefulness :notes:
   + Obviously useful for maps/directions
   + But haven't seen it used much beyond that

* L_p norm :slide:
  + Euclidean distance and Manhattan can be generalized
  + Euclidean distance referred to as L_2 norm
  + Chebyshev distance is L_âˆž
  [[file:lp_norm.png]]
** L_p space :notes:
   + Important for signal processing, math, other applications
   + You may want to study these distances for comparing wave forms, like audio

* Ordinal Distance :slide:
  + Normalize the ordinal rankings
  + Use a numerical distance metric

* Cosine Similarity :slide:
  + Jaccard similarity can work well for sets of roughly equal size
  + How to compare sets with a large difference in magnitude?
  + Model them as vectors, take the cosign of the angle between
  [[file:cosine-similarity.png]]
** Cosign :notes:
   + Why cosine? Hint: nomalization
   + img: http://cs.carleton.edu/cs_comps/0910/netflixprize/final_results/knn/index.html

* Cosine Example :slide:
  + "Jim likes pizza" | "Shreyas likes pizza"

#+STYLE: <link rel="stylesheet" type="text/css" href="production/common.css" />
#+STYLE: <link rel="stylesheet" type="text/css" href="production/screen.css" media="screen" />
#+STYLE: <link rel="stylesheet" type="text/css" href="production/projection.css" media="projection" />
#+STYLE: <link rel="stylesheet" type="text/css" href="production/color-blue.css" media="projection" />
#+STYLE: <link rel="stylesheet" type="text/css" href="production/presenter.css" media="presenter" />
#+STYLE: <link href='http://fonts.googleapis.com/css?family=Lobster+Two:700|Yanone+Kaffeesatz:700|Open+Sans' rel='stylesheet' type='text/css'>

#+BEGIN_HTML
<script type="text/javascript" src="production/org-html-slideshow.js"></script>
#+END_HTML

# Local Variables:
# org-export-html-style-include-default: nil
# org-export-html-style-include-scripts: nil
# buffer-file-coding-system: utf-8-unix
# End:
